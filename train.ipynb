{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cude\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_one_epoch(model, data_loader, criterion, device, train=False, optimizer=None):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, (inputs, labels) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / (step + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained model\n",
    "model = timm.create_model('resnet50', pretrained=True)\n",
    "\n",
    "# Preprocessing transform for model\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 128\n",
    "\n",
    "# Imagenette dataset\n",
    "train_dataset = torchvision.datasets.ImageFolder('imagenette2-320/train/', transform=transform)\n",
    "val_dataset = torchvision.datasets.ImageFolder('imagenette2-320/val', transform=transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, pin_memory=True, num_workers=5)\n",
    "val_loader = DataLoader(val_dataset, batch_size, pin_memory=True, num_workers=5)\n",
    "\n",
    "# Criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using recipe: recipe.md\n"
     ]
    }
   ],
   "source": [
    "from sparsezoo import search_models\n",
    "from sparseml.pytorch.optim import ScheduledModifierManager\n",
    "\n",
    "# zoo_model = search_models(\n",
    "#     domain=\"cv\",\n",
    "#     sub_domain=\"classification\",\n",
    "#     architecture=\"resnet_v1\",\n",
    "#     sub_architecture=\"50\",\n",
    "#     framework=\"pytorch\",\n",
    "#     repo=\"sparseml\",\n",
    "#     dataset=\"imagenette\",\n",
    "#     sparse_name=\"pruned\",\n",
    "# )[0]  # unwrap search result\n",
    "# recipe_path = zoo_model.recipes.default.path\n",
    "recipe_path = 'recipe.md'\n",
    "print(f\"Using recipe: {recipe_path}\")\n",
    "\n",
    "manager = ScheduledModifierManager.from_yaml(recipe_path)\n",
    "optimizer = manager.modify(model, optimizer, steps_per_epoch=len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 4/74 [01:32<26:49, 23.00s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "epoch = manager.min_epochs\n",
    "while epoch < manager.max_epochs:\n",
    "    train_loss = run_model_one_epoch(model, train_loader, criterion, 'cpu', train=True, optimizer=optimizer)\n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1.weight',\n",
       " 'bn1.weight',\n",
       " 'bn1.bias',\n",
       " 'layer1.0.conv1.weight',\n",
       " 'layer1.0.bn1.weight',\n",
       " 'layer1.0.bn1.bias',\n",
       " 'layer1.0.conv2.weight',\n",
       " 'layer1.0.bn2.weight',\n",
       " 'layer1.0.bn2.bias',\n",
       " 'layer1.0.conv3.weight',\n",
       " 'layer1.0.bn3.weight',\n",
       " 'layer1.0.bn3.bias',\n",
       " 'layer1.0.downsample.0.weight',\n",
       " 'layer1.0.downsample.1.weight',\n",
       " 'layer1.0.downsample.1.bias',\n",
       " 'layer1.1.conv1.weight',\n",
       " 'layer1.1.bn1.weight',\n",
       " 'layer1.1.bn1.bias',\n",
       " 'layer1.1.conv2.weight',\n",
       " 'layer1.1.bn2.weight',\n",
       " 'layer1.1.bn2.bias',\n",
       " 'layer1.1.conv3.weight',\n",
       " 'layer1.1.bn3.weight',\n",
       " 'layer1.1.bn3.bias',\n",
       " 'layer1.2.conv1.weight',\n",
       " 'layer1.2.bn1.weight',\n",
       " 'layer1.2.bn1.bias',\n",
       " 'layer1.2.conv2.weight',\n",
       " 'layer1.2.bn2.weight',\n",
       " 'layer1.2.bn2.bias',\n",
       " 'layer1.2.conv3.weight',\n",
       " 'layer1.2.bn3.weight',\n",
       " 'layer1.2.bn3.bias',\n",
       " 'layer2.0.conv1.weight',\n",
       " 'layer2.0.bn1.weight',\n",
       " 'layer2.0.bn1.bias',\n",
       " 'layer2.0.conv2.weight',\n",
       " 'layer2.0.bn2.weight',\n",
       " 'layer2.0.bn2.bias',\n",
       " 'layer2.0.conv3.weight',\n",
       " 'layer2.0.bn3.weight',\n",
       " 'layer2.0.bn3.bias',\n",
       " 'layer2.0.downsample.0.weight',\n",
       " 'layer2.0.downsample.1.weight',\n",
       " 'layer2.0.downsample.1.bias',\n",
       " 'layer2.1.conv1.weight',\n",
       " 'layer2.1.bn1.weight',\n",
       " 'layer2.1.bn1.bias',\n",
       " 'layer2.1.conv2.weight',\n",
       " 'layer2.1.bn2.weight',\n",
       " 'layer2.1.bn2.bias',\n",
       " 'layer2.1.conv3.weight',\n",
       " 'layer2.1.bn3.weight',\n",
       " 'layer2.1.bn3.bias',\n",
       " 'layer2.2.conv1.weight',\n",
       " 'layer2.2.bn1.weight',\n",
       " 'layer2.2.bn1.bias',\n",
       " 'layer2.2.conv2.weight',\n",
       " 'layer2.2.bn2.weight',\n",
       " 'layer2.2.bn2.bias',\n",
       " 'layer2.2.conv3.weight',\n",
       " 'layer2.2.bn3.weight',\n",
       " 'layer2.2.bn3.bias',\n",
       " 'layer2.3.conv1.weight',\n",
       " 'layer2.3.bn1.weight',\n",
       " 'layer2.3.bn1.bias',\n",
       " 'layer2.3.conv2.weight',\n",
       " 'layer2.3.bn2.weight',\n",
       " 'layer2.3.bn2.bias',\n",
       " 'layer2.3.conv3.weight',\n",
       " 'layer2.3.bn3.weight',\n",
       " 'layer2.3.bn3.bias',\n",
       " 'layer3.0.conv1.weight',\n",
       " 'layer3.0.bn1.weight',\n",
       " 'layer3.0.bn1.bias',\n",
       " 'layer3.0.conv2.weight',\n",
       " 'layer3.0.bn2.weight',\n",
       " 'layer3.0.bn2.bias',\n",
       " 'layer3.0.conv3.weight',\n",
       " 'layer3.0.bn3.weight',\n",
       " 'layer3.0.bn3.bias',\n",
       " 'layer3.0.downsample.0.weight',\n",
       " 'layer3.0.downsample.1.weight',\n",
       " 'layer3.0.downsample.1.bias',\n",
       " 'layer3.1.conv1.weight',\n",
       " 'layer3.1.bn1.weight',\n",
       " 'layer3.1.bn1.bias',\n",
       " 'layer3.1.conv2.weight',\n",
       " 'layer3.1.bn2.weight',\n",
       " 'layer3.1.bn2.bias',\n",
       " 'layer3.1.conv3.weight',\n",
       " 'layer3.1.bn3.weight',\n",
       " 'layer3.1.bn3.bias',\n",
       " 'layer3.2.conv1.weight',\n",
       " 'layer3.2.bn1.weight',\n",
       " 'layer3.2.bn1.bias',\n",
       " 'layer3.2.conv2.weight',\n",
       " 'layer3.2.bn2.weight',\n",
       " 'layer3.2.bn2.bias',\n",
       " 'layer3.2.conv3.weight',\n",
       " 'layer3.2.bn3.weight',\n",
       " 'layer3.2.bn3.bias',\n",
       " 'layer3.3.conv1.weight',\n",
       " 'layer3.3.bn1.weight',\n",
       " 'layer3.3.bn1.bias',\n",
       " 'layer3.3.conv2.weight',\n",
       " 'layer3.3.bn2.weight',\n",
       " 'layer3.3.bn2.bias',\n",
       " 'layer3.3.conv3.weight',\n",
       " 'layer3.3.bn3.weight',\n",
       " 'layer3.3.bn3.bias',\n",
       " 'layer3.4.conv1.weight',\n",
       " 'layer3.4.bn1.weight',\n",
       " 'layer3.4.bn1.bias',\n",
       " 'layer3.4.conv2.weight',\n",
       " 'layer3.4.bn2.weight',\n",
       " 'layer3.4.bn2.bias',\n",
       " 'layer3.4.conv3.weight',\n",
       " 'layer3.4.bn3.weight',\n",
       " 'layer3.4.bn3.bias',\n",
       " 'layer3.5.conv1.weight',\n",
       " 'layer3.5.bn1.weight',\n",
       " 'layer3.5.bn1.bias',\n",
       " 'layer3.5.conv2.weight',\n",
       " 'layer3.5.bn2.weight',\n",
       " 'layer3.5.bn2.bias',\n",
       " 'layer3.5.conv3.weight',\n",
       " 'layer3.5.bn3.weight',\n",
       " 'layer3.5.bn3.bias',\n",
       " 'layer4.0.conv1.weight',\n",
       " 'layer4.0.bn1.weight',\n",
       " 'layer4.0.bn1.bias',\n",
       " 'layer4.0.conv2.weight',\n",
       " 'layer4.0.bn2.weight',\n",
       " 'layer4.0.bn2.bias',\n",
       " 'layer4.0.conv3.weight',\n",
       " 'layer4.0.bn3.weight',\n",
       " 'layer4.0.bn3.bias',\n",
       " 'layer4.0.downsample.0.weight',\n",
       " 'layer4.0.downsample.1.weight',\n",
       " 'layer4.0.downsample.1.bias',\n",
       " 'layer4.1.conv1.weight',\n",
       " 'layer4.1.bn1.weight',\n",
       " 'layer4.1.bn1.bias',\n",
       " 'layer4.1.conv2.weight',\n",
       " 'layer4.1.bn2.weight',\n",
       " 'layer4.1.bn2.bias',\n",
       " 'layer4.1.conv3.weight',\n",
       " 'layer4.1.bn3.weight',\n",
       " 'layer4.1.bn3.bias',\n",
       " 'layer4.2.conv1.weight',\n",
       " 'layer4.2.bn1.weight',\n",
       " 'layer4.2.bn1.bias',\n",
       " 'layer4.2.conv2.weight',\n",
       " 'layer4.2.bn2.weight',\n",
       " 'layer4.2.bn2.bias',\n",
       " 'layer4.2.conv3.weight',\n",
       " 'layer4.2.bn3.weight',\n",
       " 'layer4.2.bn3.bias',\n",
       " 'fc.weight',\n",
       " 'fc.bias']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k,v in model.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('sparse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af98f0f8a2a2f397d56bd468c0e1fa01a9f37394ab1db319c010d33b05f5b031"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
